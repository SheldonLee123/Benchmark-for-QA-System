{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Activation, merge, Input, Lambda, Reshape\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, GRU, TimeDistributed, Bidirectional\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who was the american general in the pacific du...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what years the steelers won the super bowl</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what was the name of the first label elvis rec...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what was the first space shuttle to fly</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the first governor in connecticut</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question     Label\n",
       "0  who was the american general in the pacific du...  Positive\n",
       "1         what years the steelers won the super bowl  Positive\n",
       "2  what was the name of the first label elvis rec...  Positive\n",
       "3            what was the first space shuttle to fly  Positive\n",
       "4          who was the first governor in connecticut  Positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/PosNeg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = df.Question\n",
    "label = df.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(title, label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultinomialNB Classifier's Accuracy: 0.83542\n",
      "\n",
      "\n",
      "SVM Classificer's Accuracy: 0.75599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB Classifier\n",
    "vect = TfidfVectorizer(stop_words='english', token_pattern=r'\\b\\w{2,}\\b', min_df=1, max_df=0.1, ngram_range=(1,2))                          # r: Raw String 字符串不会转义\n",
    "mnb = MultinomialNB(alpha=2)              # alpha 平滑参数\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5, random_state=42)         #random_state参数的作用是为了保证每次运行程序时都以同样的方式进行分割\n",
    "mnb_pipeline = make_pipeline(vect, mnb)\n",
    "svm_pipeline = make_pipeline(vect, svm)\n",
    "mnb_cv = cross_val_score(mnb_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "svm_cv = cross_val_score(svm_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "print('\\nMultinomialNB Classifier\\'s Accuracy: %0.5f\\n' % mnb_cv.mean())\n",
    "print('\\nSVM Classificer\\'s Accuracy: %0.5f\\n' % svm_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = list(y_train.value_counts().index)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_labels)\n",
    "num_labels = len(y_labels)\n",
    "y_train = to_categorical(y_train.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "y_test = to_categorical(y_test.map(lambda x: le.transform([x])[0]), num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove word embedding data\n",
    "GLOVE_DIR = \"./glove.6B\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'), encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take tokens and build word-in dictionary\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "tokenizer.fit_on_texts(title)\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the word vector for each word in the data set from Glove\n",
    "embedding_matrix = np.zeros((len(vocab)+1, 300))\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the input format of the model\n",
    "x_train_word_ids = tokenizer.texts_to_sequences(X_train)               #序列的列表，列表中每个序列对应于一段输入文本\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(X_test)\n",
    "x_train_padded_seqs = pad_sequences(x_train_word_ids, maxlen=20)                #将序列转化为经过填充以后的一个长度相同的新序列\n",
    "x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot mlp\n",
    "x_train = tokenizer.sequences_to_matrix(x_train_word_ids, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test_word_ids, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17154 samples, validate on 1907 samples\n",
      "Epoch 1/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.1910 - accuracy: 0.9279 - val_loss: 0.1098 - val_accuracy: 0.9685\n",
      "Epoch 2/15\n",
      "17154/17154 [==============================] - 44s 3ms/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.1003 - val_accuracy: 0.9717\n",
      "Epoch 3/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.1100 - val_accuracy: 0.9680\n",
      "Epoch 4/15\n",
      "17154/17154 [==============================] - 47s 3ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.1116 - val_accuracy: 0.9685\n",
      "Epoch 5/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.1238 - val_accuracy: 0.9680\n",
      "Epoch 6/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1267 - val_accuracy: 0.9706\n",
      "Epoch 7/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 0.1426 - val_accuracy: 0.9670\n",
      "Epoch 8/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.1429 - val_accuracy: 0.9696\n",
      "Epoch 9/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1473 - val_accuracy: 0.9712\n",
      "Epoch 10/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1601 - val_accuracy: 0.9659\n",
      "Epoch 11/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1618 - val_accuracy: 0.9685\n",
      "Epoch 12/15\n",
      "17154/17154 [==============================] - 45s 3ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1659 - val_accuracy: 0.9670\n",
      "Epoch 13/15\n",
      "17154/17154 [==============================] - 44s 3ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1799 - val_accuracy: 0.9659\n",
      "Epoch 14/15\n",
      "17154/17154 [==============================] - 44s 3ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.1886 - val_accuracy: 0.9685\n",
      "Epoch 15/15\n",
      "17154/17154 [==============================] - 44s 3ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1839 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fee1b411f60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(len(vocab)+1,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=15,\n",
    "                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_predict = [\"who was the american general in the pacific during world war ii\",\"where do guyanese people live\",\"what is magic johnsons dads name\"]\n",
    "# model = load_model('./model/DenseModel.h5')\n",
    "# x_predict_word_ids = tokenizer.texts_to_sequences(X_predict)\n",
    "# x_predict = tokenizer.sequences_to_matrix(x_predict_word_ids, mode='binary')\n",
    "# predict_test = model.predict(x_predict)\n",
    "# print(np.argmax(predict_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907/1907 [==============================] - 1s 350us/step\n",
      "\n",
      "test loss:  0.1839279934978059\n",
      "\n",
      "test accuracy:  0.9669638276100159\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/DenseModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17154 samples, validate on 1907 samples\n",
      "Epoch 1/12\n",
      "17154/17154 [==============================] - 108s 6ms/step - loss: 0.1758 - accuracy: 0.9344 - val_loss: 0.0941 - val_accuracy: 0.9696\n",
      "Epoch 2/12\n",
      "17154/17154 [==============================] - 219s 13ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 3/12\n",
      "17154/17154 [==============================] - 105s 6ms/step - loss: 0.0458 - accuracy: 0.9868 - val_loss: 0.1033 - val_accuracy: 0.9675\n",
      "Epoch 4/12\n",
      "17154/17154 [==============================] - 104s 6ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.1304 - val_accuracy: 0.9601\n",
      "Epoch 5/12\n",
      "17154/17154 [==============================] - 108s 6ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.1192 - val_accuracy: 0.9680\n",
      "Epoch 6/12\n",
      "17154/17154 [==============================] - 110s 6ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.1081 - val_accuracy: 0.9712\n",
      "Epoch 7/12\n",
      "17154/17154 [==============================] - 110s 6ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.1536 - val_accuracy: 0.9685\n",
      "Epoch 8/12\n",
      "17154/17154 [==============================] - 107s 6ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1625 - val_accuracy: 0.9680\n",
      "Epoch 9/12\n",
      "17154/17154 [==============================] - 106s 6ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1533 - val_accuracy: 0.9659\n",
      "Epoch 10/12\n",
      "17154/17154 [==============================] - 106s 6ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.1860 - val_accuracy: 0.9722\n",
      "Epoch 11/12\n",
      "17154/17154 [==============================] - 106s 6ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.1378 - val_accuracy: 0.9717\n",
      "Epoch 12/12\n",
      "17154/17154 [==============================] - 106s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1792 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fed74044f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907/1907 [==============================] - 3s 2ms/step\n",
      "\n",
      "test loss:  0.17920124676290022\n",
      "\n",
      "test accuracy:  0.9727320671081543\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/RNNModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17154 samples, validate on 1907 samples\n",
      "Epoch 1/12\n",
      "17154/17154 [==============================] - 34s 2ms/step - loss: 0.1759 - accuracy: 0.9362 - val_loss: 0.0950 - val_accuracy: 0.9717\n",
      "Epoch 2/12\n",
      "17154/17154 [==============================] - 32s 2ms/step - loss: 0.0642 - accuracy: 0.9794 - val_loss: 0.1210 - val_accuracy: 0.9722\n",
      "Epoch 3/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.1360 - val_accuracy: 0.9706\n",
      "Epoch 4/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1088 - val_accuracy: 0.9680\n",
      "Epoch 5/12\n",
      "17154/17154 [==============================] - 32s 2ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.1280 - val_accuracy: 0.9628\n",
      "Epoch 6/12\n",
      "17154/17154 [==============================] - 36s 2ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1166 - val_accuracy: 0.9675\n",
      "Epoch 7/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.2397 - val_accuracy: 0.9670\n",
      "Epoch 8/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.1524 - val_accuracy: 0.9738\n",
      "Epoch 9/12\n",
      "17154/17154 [==============================] - 34s 2ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.1735 - val_accuracy: 0.9691\n",
      "Epoch 10/12\n",
      "17154/17154 [==============================] - 34s 2ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.2001 - val_accuracy: 0.9670\n",
      "Epoch 11/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.1320 - val_accuracy: 0.9696\n",
      "Epoch 12/12\n",
      "17154/17154 [==============================] - 33s 2ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1513 - val_accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fed308f6048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "\n",
    "# Convolutional moedl (3x conv, flatten, 2x dense)\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907/1907 [==============================] - 0s 255us/step\n",
      "\n",
      "test loss:  0.1512668517655798\n",
      "\n",
      "test accuracy:  0.9758783578872681\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/CNNModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17154 samples, validate on 1907 samples\n",
      "Epoch 1/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.0910 - val_accuracy: 0.9712\n",
      "Epoch 2/12\n",
      "17154/17154 [==============================] - 58s 3ms/step - loss: 0.0423 - accuracy: 0.9869 - val_loss: 0.1071 - val_accuracy: 0.9659\n",
      "Epoch 3/12\n",
      "17154/17154 [==============================] - 53s 3ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.1553 - val_accuracy: 0.9675\n",
      "Epoch 4/12\n",
      "17154/17154 [==============================] - 53s 3ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.1961 - val_accuracy: 0.9664\n",
      "Epoch 5/12\n",
      "17154/17154 [==============================] - 53s 3ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.2429 - val_accuracy: 0.9580\n",
      "Epoch 6/12\n",
      "17154/17154 [==============================] - 53s 3ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.2204 - val_accuracy: 0.9643\n",
      "Epoch 7/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.2409 - val_accuracy: 0.9607\n",
      "Epoch 8/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.2334 - val_accuracy: 0.9617\n",
      "Epoch 9/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.2697 - val_accuracy: 0.9622\n",
      "Epoch 10/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.2787 - val_accuracy: 0.9622\n",
      "Epoch 11/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.3065 - val_accuracy: 0.9570\n",
      "Epoch 12/12\n",
      "17154/17154 [==============================] - 52s 3ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.3062 - val_accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fed2bafa208>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextCNN\n",
    "main_input = Input(shape=(20,), dtype='float64')\n",
    "embedder = Embedding(len(vocab) + 1, 300, input_length = 20)\n",
    "embed = embedder(main_input)\n",
    "cnn1 = Convolution1D(256, 3, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn1 = MaxPool1D(pool_size=4)(cnn1)\n",
    "cnn2 = Convolution1D(256, 4, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn2 = MaxPool1D(pool_size=4)(cnn2)\n",
    "cnn3 = Convolution1D(256, 5, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn3 = MaxPool1D(pool_size=4)(cnn3)\n",
    "cnn = concatenate([cnn1,cnn2,cnn3], axis=-1)\n",
    "flat = Flatten()(cnn)\n",
    "drop = Dropout(0.2)(flat)\n",
    "main_output = Dense(num_labels, activation='softmax')(drop)\n",
    "model = Model(inputs = main_input, outputs = main_output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=12,\n",
    "          validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907/1907 [==============================] - 1s 575us/step\n",
      "\n",
      "test loss:  0.3062174772522096\n",
      "\n",
      "test accuracy:  0.966439425945282\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/TextCNNModel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
