{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Activation, merge, Input, Lambda, Reshape\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, GRU, TimeDistributed, Bidirectional\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>who was the american general in the pacific du...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>what years the steelers won the super bowl</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>what was the name of the first label elvis rec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>what was the first space shuttle to fly</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>who was the first governor in connecticut</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question     label\n",
       "0   0  who was the american general in the pacific du...  positive\n",
       "1   0         what years the steelers won the super bowl  positive\n",
       "2   0  what was the name of the first label elvis rec...  positive\n",
       "3   0            what was the first space shuttle to fly  positive\n",
       "4   0          who was the first governor in connecticut  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/PosNeg2.0.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = df.question\n",
    "label = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(title, label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultinomialNB Classifier's Accuracy: 0.86505\n",
      "\n",
      "\n",
      "SVM Classificer's Accuracy: 0.73237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB Classifier\n",
    "vect = TfidfVectorizer(stop_words='english', token_pattern=r'\\b\\w{2,}\\b', min_df=1, max_df=0.1, ngram_range=(1,2))                          # r: Raw String 字符串不会转义\n",
    "mnb = MultinomialNB(alpha=2)              # alpha 平滑参数\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5, random_state=42)         #random_state参数的作用是为了保证每次运行程序时都以同样的方式进行分割\n",
    "mnb_pipeline = make_pipeline(vect, mnb)\n",
    "svm_pipeline = make_pipeline(vect, svm)\n",
    "mnb_cv = cross_val_score(mnb_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "svm_cv = cross_val_score(svm_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "print('\\nMultinomialNB Classifier\\'s Accuracy: %0.5f\\n' % mnb_cv.mean())\n",
    "print('\\nSVM Classificer\\'s Accuracy: %0.5f\\n' % svm_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = list(y_train.value_counts().index)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_labels)\n",
    "num_labels = len(y_labels)\n",
    "y_train = to_categorical(y_train.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "y_test = to_categorical(y_test.map(lambda x: le.transform([x])[0]), num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove word embedding data\n",
    "GLOVE_DIR = \"./glove.6B\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'), encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take tokens and build word-in dictionary\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "tokenizer.fit_on_texts(title)\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the word vector for each word in the data set from Glove\n",
    "embedding_matrix = np.zeros((len(vocab)+1, 300))\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the input format of the model\n",
    "x_train_word_ids = tokenizer.texts_to_sequences(X_train)               #序列的列表，列表中每个序列对应于一段输入文本\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(X_test)\n",
    "x_train_padded_seqs = pad_sequences(x_train_word_ids, maxlen=20)                #将序列转化为经过填充以后的一个长度相同的新序列\n",
    "x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot mlp\n",
    "x_train = tokenizer.sequences_to_matrix(x_train_word_ids, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test_word_ids, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(len(vocab)+1,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=15,\n",
    "                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_predict = [\"who was the american general in the pacific during world war ii\",\"where do guyanese people live\",\"what is magic johnsons dads name\"]\n",
    "# model = load_model('./model/DenseModel.h5')\n",
    "# x_predict_word_ids = tokenizer.texts_to_sequences(X_predict)\n",
    "# x_predict = tokenizer.sequences_to_matrix(x_predict_word_ids, mode='binary')\n",
    "# predict_test = model.predict(x_predict)\n",
    "# print(np.argmax(predict_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/DenseModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/RNNModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "\n",
    "# Convolutional moedl (3x conv, flatten, 2x dense)\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/CNNModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextCNN\n",
    "main_input = Input(shape=(20,), dtype='float64')\n",
    "embedder = Embedding(len(vocab) + 1, 300, input_length = 20)\n",
    "embed = embedder(main_input)\n",
    "cnn1 = Convolution1D(256, 3, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn1 = MaxPool1D(pool_size=4)(cnn1)\n",
    "cnn2 = Convolution1D(256, 4, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn2 = MaxPool1D(pool_size=4)(cnn2)\n",
    "cnn3 = Convolution1D(256, 5, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn3 = MaxPool1D(pool_size=4)(cnn3)\n",
    "cnn = concatenate([cnn1,cnn2,cnn3], axis=-1)\n",
    "flat = Flatten()(cnn)\n",
    "drop = Dropout(0.2)(flat)\n",
    "main_output = Dense(num_labels, activation='softmax')(drop)\n",
    "model = Model(inputs = main_input, outputs = main_output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=12,\n",
    "          validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/TextCNNModel2.0.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
