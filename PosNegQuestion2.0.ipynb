{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Activation, merge, Input, Lambda, Reshape\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, GRU, TimeDistributed, Bidirectional\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>who was the american general in the pacific du...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>what years the steelers won the super bowl</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>what was the name of the first label elvis rec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>what was the first space shuttle to fly</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>who was the first governor in connecticut</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question     label\n",
       "0   0  who was the american general in the pacific du...  positive\n",
       "1   0         what years the steelers won the super bowl  positive\n",
       "2   0  what was the name of the first label elvis rec...  positive\n",
       "3   0            what was the first space shuttle to fly  positive\n",
       "4   0          who was the first governor in connecticut  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/PosNeg2.0.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = df.question\n",
    "label = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(title, label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultinomialNB Classifier's Accuracy: 0.86504\n",
      "\n",
      "\n",
      "SVM Classificer's Accuracy: 0.73240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB Classifier\n",
    "vect = TfidfVectorizer(stop_words='english', token_pattern=r'\\b\\w{2,}\\b', min_df=1, max_df=0.1, ngram_range=(1,2))                          # r: Raw String 字符串不会转义\n",
    "mnb = MultinomialNB(alpha=2)              # alpha 平滑参数\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5, random_state=42)         #random_state参数的作用是为了保证每次运行程序时都以同样的方式进行分割\n",
    "mnb_pipeline = make_pipeline(vect, mnb)\n",
    "svm_pipeline = make_pipeline(vect, svm)\n",
    "mnb_cv = cross_val_score(mnb_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "svm_cv = cross_val_score(svm_pipeline, title, label, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "print('\\nMultinomialNB Classifier\\'s Accuracy: %0.5f\\n' % mnb_cv.mean())\n",
    "print('\\nSVM Classificer\\'s Accuracy: %0.5f\\n' % svm_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = list(y_train.value_counts().index)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_labels)\n",
    "num_labels = len(y_labels)\n",
    "y_train = to_categorical(y_train.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "y_test = to_categorical(y_test.map(lambda x: le.transform([x])[0]), num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove word embedding data\n",
    "GLOVE_DIR = \"./glove.6B\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'), encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take tokens and build word-in dictionary\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "tokenizer.fit_on_texts(title)\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the word vector for each word in the data set from Glove\n",
    "embedding_matrix = np.zeros((len(vocab)+1, 300))\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the input format of the model\n",
    "x_train_word_ids = tokenizer.texts_to_sequences(X_train)               #序列的列表，列表中每个序列对应于一段输入文本\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(X_test)\n",
    "x_train_padded_seqs = pad_sequences(x_train_word_ids, maxlen=20)                #将序列转化为经过填充以后的一个长度相同的新序列\n",
    "x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot mlp\n",
    "x_train = tokenizer.sequences_to_matrix(x_train_word_ids, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test_word_ids, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28822 samples, validate on 3203 samples\n",
      "Epoch 1/15\n",
      "28822/28822 [==============================] - 129s 4ms/step - loss: 0.1608 - accuracy: 0.9366 - val_loss: 0.1041 - val_accuracy: 0.9644\n",
      "Epoch 2/15\n",
      "28822/28822 [==============================] - 132s 5ms/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0906 - val_accuracy: 0.9700\n",
      "Epoch 3/15\n",
      "28822/28822 [==============================] - 126s 4ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.0902 - val_accuracy: 0.9669\n",
      "Epoch 4/15\n",
      "28822/28822 [==============================] - 126s 4ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0922 - val_accuracy: 0.9694\n",
      "Epoch 5/15\n",
      "28822/28822 [==============================] - 125s 4ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0988 - val_accuracy: 0.9710\n",
      "Epoch 6/15\n",
      "28822/28822 [==============================] - 125s 4ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1070 - val_accuracy: 0.9707\n",
      "Epoch 7/15\n",
      "28822/28822 [==============================] - 128s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1195 - val_accuracy: 0.9660\n",
      "Epoch 8/15\n",
      "28822/28822 [==============================] - 123s 4ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1139 - val_accuracy: 0.9716\n",
      "Epoch 9/15\n",
      "28822/28822 [==============================] - 129s 4ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1227 - val_accuracy: 0.9688\n",
      "Epoch 10/15\n",
      "28822/28822 [==============================] - 135s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1270 - val_accuracy: 0.9697\n",
      "Epoch 11/15\n",
      "28822/28822 [==============================] - 164s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1314 - val_accuracy: 0.9672\n",
      "Epoch 12/15\n",
      "28822/28822 [==============================] - 169s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1307 - val_accuracy: 0.9707\n",
      "Epoch 13/15\n",
      "28822/28822 [==============================] - 166s 6ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1377 - val_accuracy: 0.9682\n",
      "Epoch 14/15\n",
      "28822/28822 [==============================] - 169s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1449 - val_accuracy: 0.9694\n",
      "Epoch 15/15\n",
      "28822/28822 [==============================] - 171s 6ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1502 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6eb9488f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(len(vocab)+1,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=15,\n",
    "                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_predict = [\"who was the american general in the pacific during world war ii\",\"where do guyanese people live\",\"what is magic johnsons dads name\"]\n",
    "# model = load_model('./model/DenseModel.h5')\n",
    "# x_predict_word_ids = tokenizer.texts_to_sequences(X_predict)\n",
    "# x_predict = tokenizer.sequences_to_matrix(x_predict_word_ids, mode='binary')\n",
    "# predict_test = model.predict(x_predict)\n",
    "# print(np.argmax(predict_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203/3203 [==============================] - 2s 749us/step\n",
      "\n",
      "test loss:  0.15024054286391028\n",
      "\n",
      "test accuracy:  0.9687792658805847\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28822/28822 [==============================] - 21s 741us/step\n",
      "\n",
      "test loss:  0.0013134197414771966\n",
      "\n",
      "test accuracy:  0.9996530413627625\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/DenseModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28822 samples, validate on 3203 samples\n",
      "Epoch 1/12\n",
      "28822/28822 [==============================] - 329s 11ms/step - loss: 0.1539 - accuracy: 0.9429 - val_loss: 0.0987 - val_accuracy: 0.9666\n",
      "Epoch 2/12\n",
      "28822/28822 [==============================] - 375s 13ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.1134 - val_accuracy: 0.9647\n",
      "Epoch 3/12\n",
      "28822/28822 [==============================] - 398s 14ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.1230 - val_accuracy: 0.9669\n",
      "Epoch 4/12\n",
      "28822/28822 [==============================] - 398s 14ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.1128 - val_accuracy: 0.9700\n",
      "Epoch 5/12\n",
      "28822/28822 [==============================] - 367s 13ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.1444 - val_accuracy: 0.9682\n",
      "Epoch 6/12\n",
      "28822/28822 [==============================] - 408s 14ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.1687 - val_accuracy: 0.9675\n",
      "Epoch 7/12\n",
      "28822/28822 [==============================] - 417s 14ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1701 - val_accuracy: 0.9685\n",
      "Epoch 8/12\n",
      "28822/28822 [==============================] - 386s 13ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1509 - val_accuracy: 0.9688\n",
      "Epoch 9/12\n",
      "28822/28822 [==============================] - 349s 12ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1447 - val_accuracy: 0.9688\n",
      "Epoch 10/12\n",
      "28822/28822 [==============================] - 297s 10ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1605 - val_accuracy: 0.9710\n",
      "Epoch 11/12\n",
      "28822/28822 [==============================] - 348s 12ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.1732 - val_accuracy: 0.9716\n",
      "Epoch 12/12\n",
      "28822/28822 [==============================] - 355s 12ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.1945 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6d2c500e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203/3203 [==============================] - 7s 2ms/step\n",
      "\n",
      "test loss:  0.19445796931452006\n",
      "\n",
      "test accuracy:  0.9709647297859192\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/RNNModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28822 samples, validate on 3203 samples\n",
      "Epoch 1/12\n",
      "28822/28822 [==============================] - 120s 4ms/step - loss: 0.1637 - accuracy: 0.9400 - val_loss: 0.1072 - val_accuracy: 0.9703\n",
      "Epoch 2/12\n",
      "28822/28822 [==============================] - 126s 4ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.1421 - val_accuracy: 0.9700\n",
      "Epoch 3/12\n",
      "28822/28822 [==============================] - 96s 3ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 0.1401 - val_accuracy: 0.9688\n",
      "Epoch 4/12\n",
      "28822/28822 [==============================] - 112s 4ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.1374 - val_accuracy: 0.9682\n",
      "Epoch 5/12\n",
      "28822/28822 [==============================] - 123s 4ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.1583 - val_accuracy: 0.9703\n",
      "Epoch 6/12\n",
      "28822/28822 [==============================] - 142s 5ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.1283 - val_accuracy: 0.9735\n",
      "Epoch 7/12\n",
      "28822/28822 [==============================] - 141s 5ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1193 - val_accuracy: 0.9710\n",
      "Epoch 8/12\n",
      "28822/28822 [==============================] - 141s 5ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.1737 - val_accuracy: 0.9722\n",
      "Epoch 9/12\n",
      "28822/28822 [==============================] - 140s 5ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1812 - val_accuracy: 0.9719\n",
      "Epoch 10/12\n",
      "28822/28822 [==============================] - 142s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.1440 - val_accuracy: 0.9710\n",
      "Epoch 11/12\n",
      "28822/28822 [==============================] - 103s 4ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.1904 - val_accuracy: 0.9669\n",
      "Epoch 12/12\n",
      "28822/28822 [==============================] - 101s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1760 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6d2659f978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab)+1, 256, input_length=20))\n",
    "\n",
    "# Convolutional moedl (3x conv, flatten, 2x dense)\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPool1D(3, 3, padding='same'))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                                 optimizer='adam',\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=12,\n",
    "                     validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203/3203 [==============================] - 1s 304us/step\n",
      "\n",
      "test loss:  0.1759534714744634\n",
      "\n",
      "test accuracy:  0.9703403115272522\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/CNNModel2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheldon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28822 samples, validate on 3203 samples\n",
      "Epoch 1/12\n",
      "28822/28822 [==============================] - 163s 6ms/step - loss: 0.1363 - accuracy: 0.9494 - val_loss: 0.0982 - val_accuracy: 0.9713\n",
      "Epoch 2/12\n",
      "28822/28822 [==============================] - 174s 6ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.0974 - val_accuracy: 0.9678\n",
      "Epoch 3/12\n",
      "28822/28822 [==============================] - 167s 6ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.1278 - val_accuracy: 0.9685\n",
      "Epoch 4/12\n",
      "28822/28822 [==============================] - 163s 6ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.1285 - val_accuracy: 0.9644\n",
      "Epoch 5/12\n",
      "28822/28822 [==============================] - 163s 6ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.1566 - val_accuracy: 0.9682\n",
      "Epoch 6/12\n",
      "28822/28822 [==============================] - 162s 6ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.1725 - val_accuracy: 0.9685\n",
      "Epoch 7/12\n",
      "28822/28822 [==============================] - 161s 6ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1610 - val_accuracy: 0.9735\n",
      "Epoch 8/12\n",
      "28822/28822 [==============================] - 161s 6ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1949 - val_accuracy: 0.9688\n",
      "Epoch 9/12\n",
      "28822/28822 [==============================] - 160s 6ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.2085 - val_accuracy: 0.9716\n",
      "Epoch 10/12\n",
      "28822/28822 [==============================] - 158s 5ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.2170 - val_accuracy: 0.9703\n",
      "Epoch 11/12\n",
      "28822/28822 [==============================] - 140s 5ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.2641 - val_accuracy: 0.9666\n",
      "Epoch 12/12\n",
      "28822/28822 [==============================] - 131s 5ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.2452 - val_accuracy: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6d2674b390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextCNN\n",
    "main_input = Input(shape=(20,), dtype='float64')\n",
    "embedder = Embedding(len(vocab) + 1, 300, input_length = 20)\n",
    "embed = embedder(main_input)\n",
    "cnn1 = Convolution1D(256, 3, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn1 = MaxPool1D(pool_size=4)(cnn1)\n",
    "cnn2 = Convolution1D(256, 4, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn2 = MaxPool1D(pool_size=4)(cnn2)\n",
    "cnn3 = Convolution1D(256, 5, padding='same', strides = 1, activation='relu')(embed)\n",
    "cnn3 = MaxPool1D(pool_size=4)(cnn3)\n",
    "cnn = concatenate([cnn1,cnn2,cnn3], axis=-1)\n",
    "flat = Flatten()(cnn)\n",
    "drop = Dropout(0.2)(flat)\n",
    "main_output = Dense(num_labels, activation='softmax')(drop)\n",
    "model = Model(inputs = main_input, outputs = main_output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded_seqs, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=12,\n",
    "          validation_data=(x_test_padded_seqs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203/3203 [==============================] - 2s 766us/step\n",
      "\n",
      "test loss:  0.24524632962464948\n",
      "\n",
      "test accuracy:  0.9719013571739197\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded_seqs, y_test)\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/TextCNNModel2.0.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
